{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create co-occurence networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates co-occurence networks and exports them to .gexf-files, either at the start of a new book or chapter or one network for all selected books and chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# which Bible passages to create co-occurence networks for\n",
    "# -1 matches the last chapter/verse. Useful when selecting a whole book/chapter\n",
    "passages = {\n",
    "    \"Psalmi\": [3,1,3,-1]\n",
    "}\n",
    "\n",
    "# export path. Exports to notebook path if empty\n",
    "path = \"\"\n",
    "\n",
    "# what range the co-occurence networks should have\n",
    "# creates new file and network at the start of a new \"chapter\", \"book\" or never when set to \"bible\"\n",
    "network_range = \"book\"\n",
    "\n",
    "# include / exclude named entitity types:\n",
    "# \"pers\" = person\n",
    "# \"mens\" = measurement unit\n",
    "# \"gens\" = people\n",
    "# \"topo\" = place\n",
    "# \"ppde\" = demonstrative personal pronoun\n",
    "# \"\"     = not specified (seems to be the 'gentillic' words, i.e. from which country someone is)\n",
    "allowed_nametypes = [\"pers\", \"mens\", \"gens\", \"topo\", \"ppde\", \"\"]\n",
    "#allowed_nametypes = [\"pers\"]\n",
    "\n",
    "# enable other_words to allow words apart from names to be included in network\n",
    "other_words = True\n",
    "# allowed_prs contains the grammatical functions of phrases that are included\n",
    "allowed_prs = ['PreC', 'Pred', 'PreO', 'PreS', 'PtcO']\n",
    "\n",
    "# minimum weight an edge should have before it is added to the output file\n",
    "min_edge_weight = 0.1\n",
    "\n",
    "# formula for the weight between words dependent on the distance in amount of sentences / words\n",
    "def get_weight_sentence(src, tgt):\n",
    "    return 1/(abs(src - tgt)+1)**2\n",
    "def get_weight_word(src, tgt):\n",
    "    return 1/(abs(src - tgt)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the python modules, the plot modules, the LAF-Fabric module (``laf``) and initialize the ``laf`` processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s This is LAF-Fabric 4.5.4\n",
      "API reference: http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n",
      "Feature doc: http://shebanq-doc.readthedocs.org/en/latest/texts/welcome.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import collections\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import networkx as nx\n",
    "from laf.fabric import LafFabric\n",
    "fabric = LafFabric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s LOADING API: please wait ... \n",
      "  0.03s INFO: USING DATA COMPILED AT: 2014-10-23T15-58-52\n",
      "  0.07s INFO: USING DATA COMPILED AT: 2014-11-27T12-37-00\n",
      "  7.58s LOGFILE=C:\\Users\\Frederik/laf-fabric-output/etcbc4/Psalmi/__log__Psalmi.txt\n",
      "  7.58s INFO: DATA LOADED FROM SOURCE etcbc4 AND ANNOX lexicon FOR TASK Psalmi AT 2016-09-28T10-05-58\n"
     ]
    }
   ],
   "source": [
    "fabric.load('etcbc4', 'lexicon', '_'.join(passages.keys()),\n",
    "{\n",
    "    \"primary\": False,\n",
    "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
    "    \"features\": (\"otype book chapter verse number lex_utf8 gloss sp prs ls nametype g_prs_utf8 ps nu gn function\", \"\"),\n",
    "},)\n",
    "exec(fabric.localnames.format(var='fabric'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Re)set all variables. If you want to run the notebook again, also run this code block again to make sure no leftovers from the previous run are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace -1 in 'passages' dict with inf. b=book, cv=chapter, verse\n",
    "for b, cv in passages.items():\n",
    "    for idx, item in enumerate(cv):\n",
    "        if item == -1:\n",
    "            cv[idx] = float('inf')\n",
    "    passages[b] = cv\n",
    "    \n",
    "suffix_person_dict = {'NJ': ['I'],\n",
    "    'J': ['I'],\n",
    "    'NW': ['We'],\n",
    "    'K': ['Myou'],\n",
    "    'K=': ['Fyou'],\n",
    "    'KM': ['Mpyou'],\n",
    "    'KN': ['Fpyou'],\n",
    "    'W': ['He'],\n",
    "    'HW': ['He'],\n",
    "    'H': ['She'],\n",
    "    'HJ': ['She'],       \n",
    "    'HM': ['Mpthey'],\n",
    "    'M': ['Mpthey'],\n",
    "    'MW': ['Mpthey'],            \n",
    "    'HN': ['Fpthey'],\n",
    "    'N': ['Fpthey'],\n",
    "    'absent': [''],\n",
    "    'n/a': ['']\n",
    "}\n",
    "\n",
    "def get_unique_lexeme(book_name, chapter_nr, lexeme):\n",
    "    if network_range == \"chapter\":\n",
    "        return \"{}_{}_{}\".format(book_name, chapter_nr, lexeme)\n",
    "    elif network_range == \"book\":\n",
    "        return \"{}_{}\".format(book_name, lexeme)\n",
    "    else:\n",
    "        return lexeme\n",
    "\n",
    "bible_index = collections.defaultdict(lambda: [])\n",
    "unique_labels = []\n",
    "unique_nodes = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda:0))))\n",
    "correct_verse = False\n",
    "node_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk through the relevant nodes and collect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3.03s Done\n"
     ]
    }
   ],
   "source": [
    "for node in NN():\n",
    "    this_type = F.otype.v(node)\n",
    "\n",
    "    # when arriving at a new verse, check if that verse is in the allowed passages\n",
    "    if this_type == \"verse\":\n",
    "        correct_verse = False\n",
    "        this_book = F.book.v(node)\n",
    "\n",
    "        for b, cv in passages.items():\n",
    "            this_chapter = int(F.chapter.v(node))\n",
    "\n",
    "            if this_book == b and this_chapter >= cv[0] and this_chapter <= cv[2]:\n",
    "                this_verse = int(F.verse.v(node))\n",
    "                \n",
    "                if cv[0] == cv[2]:\n",
    "                    if this_verse >= cv[1] and this_verse <= cv[3]:\n",
    "                        correct_verse = True\n",
    "                        break\n",
    "                elif (\n",
    "                    (this_chapter == cv[0] and this_verse >= cv[1]) or\n",
    "                    (this_chapter > cv[0] and this_chapter < cv[2]) or\n",
    "                    (this_chapter == cv[2] and this_verse <= cv[3])\n",
    "                   ):\n",
    "                    \n",
    "                    correct_verse = True\n",
    "                    break\n",
    "                \n",
    "    # if the verse is allowed, continue\n",
    "    if correct_verse:\n",
    "        if this_type == \"verse\":\n",
    "            this_verse = int(F.verse.v(node))\n",
    "            if not this_chapter in bible_index[this_book]:\n",
    "                bible_index[this_book].append(this_chapter)\n",
    "        \n",
    "        elif this_type == \"sentence\":\n",
    "            sentence_nr = int(F.number.v(node))\n",
    "        \n",
    "        elif this_type == \"phrase\":\n",
    "            this_phrase = node\n",
    "        \n",
    "        elif this_type == \"word\":           \n",
    "            word_nr = int(F.number.v(node))\n",
    "            sp = F.sp.v(node)\n",
    "            lexeme = F.lex_utf8.v(node)\n",
    "            nametype = F.nametype.v(node)\n",
    "            english_name = re.sub(r'\\W+', '', F.gloss.v(node))\n",
    "            allowed_nametype = any(x in nametype.split(',') for x in allowed_nametypes)\n",
    "            unique_lexeme = get_unique_lexeme(this_book, this_chapter, lexeme)\n",
    "            \n",
    "            #Pronominal suffix -consonantal-transliterated prs toevoegen, word niveau\n",
    "            prs = F.g_prs_utf8.v(node)\n",
    "            prs_trans = suffix_person_dict[F.prs.v(node)][0]\n",
    "\n",
    "            # if part of speech == proper noun or lexical set == gentilic and nametype\n",
    "            if (sp == 'nmpr' or F.ls.v(node) == 'gntl') and allowed_nametype:\n",
    "\n",
    "                # if the word is not yet in the chapter / book / bible, add it\n",
    "                if unique_lexeme not in unique_nodes:\n",
    "                    unique_nodes[unique_lexeme][\"id\"] = node_id\n",
    "                    node_id += 1\n",
    "                    \n",
    "                    # if english name already exists, add a 2 (for clarity)\n",
    "                    if [lexeme, english_name] not in unique_labels:\n",
    "                        english_names = [x[1] for x in unique_labels]\n",
    "                        while english_name in english_names and [lexeme, english_name] not in unique_labels:\n",
    "                            english_name += \"2\"\n",
    "                        if [lexeme, english_name] not in unique_labels:\n",
    "                            unique_labels.append([lexeme, english_name])\n",
    "                    \n",
    "                    unique_nodes[unique_lexeme][\"gloss\"] = english_name\n",
    "                    unique_nodes[unique_lexeme][\"lexeme\"] = lexeme\n",
    "                    unique_nodes[unique_lexeme][\"nametype\"] = nametype\n",
    "                    unique_nodes[unique_lexeme][\"part_of_speech\"] = sp\n",
    "                    \n",
    "                    occurrence = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda: [])))\n",
    "                    occurrence[this_book][this_chapter][\"sentence_nr\"] = [sentence_nr]\n",
    "                    occurrence[this_book][this_chapter][\"word_nr\"] = [word_nr]\n",
    "                    occurrence[this_book][this_chapter][\"verse\"] =  [this_verse]\n",
    "                    unique_nodes[unique_lexeme][\"occurrence\"] = occurrence\n",
    "                # otherwise only add the occurence information\n",
    "                else:\n",
    "                    unique_nodes[unique_lexeme][\"occurrence\"][this_book][this_chapter][\"verse\"].append(this_verse)\n",
    "                    unique_nodes[unique_lexeme][\"occurrence\"][this_book][this_chapter][\"sentence_nr\"].append(sentence_nr)\n",
    "                    unique_nodes[unique_lexeme][\"occurrence\"][this_book][this_chapter][\"word_nr\"].append(word_nr)\n",
    "\n",
    "            ### extensions for Christiaan Erwich\n",
    "            \n",
    "            # each personal pronoun, demonstrative pronoun and word with a suffix gets a unique node\n",
    "            elif (sp == 'prps' or sp == 'ppde' or prs) and other_words:\n",
    "                unique_lexeme = '{}_unique{}'.format(unique_lexeme, node_id)\n",
    "                unique_nodes[unique_lexeme][\"id\"] = node_id\n",
    "                node_id += 1\n",
    "\n",
    "                unique_nodes[unique_lexeme][\"gloss\"] = english_name\n",
    "                unique_nodes[unique_lexeme][\"lexeme\"] = lexeme\n",
    "                unique_nodes[unique_lexeme][\"part_of_speech\"] = sp\n",
    "                \n",
    "                occurrence = collections.defaultdict(lambda: collections.defaultdict(lambda: collections.defaultdict(lambda: [])))\n",
    "                occurrence[this_book][this_chapter][\"sentence_nr\"] = [sentence_nr]\n",
    "                occurrence[this_book][this_chapter][\"word_nr\"] = [word_nr]\n",
    "                occurrence[this_book][this_chapter][\"verse\"] = [this_verse]\n",
    "                unique_nodes[unique_lexeme][\"occurrence\"] = occurrence\n",
    "                \n",
    "                # if the word has a suffix add suffix-property\n",
    "                if prs:\n",
    "                    unique_nodes[unique_lexeme][\"suffix\"] = prs\n",
    "                    unique_nodes[unique_lexeme][\"suffix_trans\"] = prs_trans\n",
    "                    \n",
    "                    # if the word is a verb\n",
    "                    if sp == 'verb':\n",
    "                        \n",
    "                        # add pgn-property\n",
    "                        pgn = ''\n",
    "                        if F.ps.v(node) == 'unknown':\n",
    "                            pgn += 'u'\n",
    "                        else:\n",
    "                            pgn += str(F.ps.v(node))\n",
    "                        if F.gn.v(node) == 'unknown':\n",
    "                            pgn += 'u'\n",
    "                        else:\n",
    "                            pgn += str(F.gn.v(node))\n",
    "                        if F.nu.v(node) == 'unknown':\n",
    "                            pgn += 'u'\n",
    "                        else:\n",
    "                            pgn += str(F.nu.v(node))\n",
    "                            \n",
    "                        unique_nodes[unique_lexeme][\"pgn\"] = pgn\n",
    "\n",
    "                        # if the phrase function is present in allowed_prs add phrase_function-property\n",
    "                        phrase_function = F.function.v(this_phrase)\n",
    "                        if phrase_function in allowed_prs:\n",
    "                            unique_nodes[unique_lexeme][\"phrase_function\"] = phrase_function\n",
    "\n",
    "msg(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Psalmi_\\u05d1\\u05e8\\u05d7[_unique1\": {\n",
      "        \"pgn\": \"uuu\",\n",
      "        \"suffix\": \"+\\u05b9\\u05d5\",\n",
      "        \"id\": 1,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        1\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        1\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        208\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05d1\\u05e8\\u05d7[\",\n",
      "        \"phrase_function\": \"PreS\",\n",
      "        \"suffix_trans\": \"He\",\n",
      "        \"gloss\": \"runaway\",\n",
      "        \"part_of_speech\": \"verb\"\n",
      "    },\n",
      "    \"Psalmi_\\u05d0\\u05e0\\u05d9_unique16\": {\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        14\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        6\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        249\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"id\": 16,\n",
      "        \"lexeme\": \"\\u05d0\\u05e0\\u05d9\",\n",
      "        \"gloss\": \"i\",\n",
      "        \"part_of_speech\": \"prps\"\n",
      "    },\n",
      "    \"Psalmi_\\u05d9\\ufb2a\\u05e2[_unique19\": {\n",
      "        \"pgn\": \"p2msg\",\n",
      "        \"suffix\": \"+\\u05b5\\u05e0\\u05b4\\u05d9\",\n",
      "        \"id\": 19,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        20\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        8\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        268\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05d9\\ufb2a\\u05e2[\",\n",
      "        \"suffix_trans\": \"I\",\n",
      "        \"gloss\": \"help\",\n",
      "        \"part_of_speech\": \"verb\"\n",
      "    },\n",
      "    \"Psalmi_\\u05e2\\u05dd/_unique22\": {\n",
      "        \"suffix\": \"+\\u05b0\\u05db\\u05b8\",\n",
      "        \"id\": 22,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        23\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        9\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        284\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05e2\\u05dd/\",\n",
      "        \"suffix_trans\": \"Myou\",\n",
      "        \"gloss\": \"people\",\n",
      "        \"part_of_speech\": \"subs\"\n",
      "    },\n",
      "    \"Psalmi_\\u05d0\\u05ea\\u05d4_unique9\": {\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        8\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        4\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        231\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"id\": 9,\n",
      "        \"lexeme\": \"\\u05d0\\u05ea\\u05d4\",\n",
      "        \"gloss\": \"you\",\n",
      "        \"part_of_speech\": \"prps\"\n",
      "    },\n",
      "    \"Psalmi_\\u05d1\\u05e8\\u05db\\u05d4/_unique23\": {\n",
      "        \"suffix\": \"+\\u05b6\\u05db\\u05b8\",\n",
      "        \"id\": 23,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        23\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        9\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        285\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05d1\\u05e8\\u05db\\u05d4/\",\n",
      "        \"suffix_trans\": \"Myou\",\n",
      "        \"gloss\": \"blessing\",\n",
      "        \"part_of_speech\": \"subs\"\n",
      "    },\n",
      "    \"Psalmi_\\u05e7\\u05d3\\ufb2a/_unique15\": {\n",
      "        \"suffix\": \"+\\u05b9\\u05d5\",\n",
      "        \"id\": 15,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        12\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        5\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        247\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05e7\\u05d3\\ufb2a/\",\n",
      "        \"suffix_trans\": \"He\",\n",
      "        \"gloss\": \"holiness\",\n",
      "        \"part_of_speech\": \"subs\"\n",
      "    },\n",
      "    \"Psalmi_\\u05d0\\u05dc\\u05d4\\u05d9\\u05dd/_unique20\": {\n",
      "        \"suffix\": \"+\",\n",
      "        \"id\": 20,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        20\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        8\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        269\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05d0\\u05dc\\u05d4\\u05d9\\u05dd/\",\n",
      "        \"suffix_trans\": \"I\",\n",
      "        \"gloss\": \"gods\",\n",
      "        \"part_of_speech\": \"subs\"\n",
      "    },\n",
      "    \"Psalmi_\\u05d3\\u05d5\\u05d3==/\": {\n",
      "        \"id\": 0,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        1\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        1\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        206\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"nametype\": \"pers\",\n",
      "        \"lexeme\": \"\\u05d3\\u05d5\\u05d3==/\",\n",
      "        \"gloss\": \"David\",\n",
      "        \"part_of_speech\": \"nmpr\"\n",
      "    },\n",
      "    \"Psalmi_\\u05d0\\u05d9\\u05d1[_unique21\": {\n",
      "        \"pgn\": \"umpl\",\n",
      "        \"suffix\": \"+\",\n",
      "        \"id\": 21,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        21\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        8\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        274\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05d0\\u05d9\\u05d1[\",\n",
      "        \"suffix_trans\": \"I\",\n",
      "        \"gloss\": \"behostile\",\n",
      "        \"part_of_speech\": \"verb\"\n",
      "    },\n",
      "    \"Psalmi_\\u05e1\\u05de\\u05da[_unique17\": {\n",
      "        \"pgn\": \"p3msg\",\n",
      "        \"suffix\": \"+\\u05b5\\u05e0\\u05b4\\u05d9\",\n",
      "        \"id\": 17,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        17\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        6\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        256\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05e1\\u05de\\u05da[\",\n",
      "        \"suffix_trans\": \"I\",\n",
      "        \"gloss\": \"support\",\n",
      "        \"part_of_speech\": \"verb\"\n",
      "    },\n",
      "    \"Psalmi_\\u05e0\\u05e4\\ufb2a/_unique7\": {\n",
      "        \"suffix\": \"+\\u05b4\\u05d9\",\n",
      "        \"id\": 7,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        5\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        3\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        223\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05e0\\u05e4\\ufb2a/\",\n",
      "        \"suffix_trans\": \"I\",\n",
      "        \"gloss\": \"soul\",\n",
      "        \"part_of_speech\": \"subs\"\n",
      "    },\n",
      "    \"Psalmi_\\u05d1\\u05df/_unique3\": {\n",
      "        \"suffix\": \"+\\u05b9\\u05d5\",\n",
      "        \"id\": 3,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        1\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        1\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        212\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05d1\\u05df/\",\n",
      "        \"suffix_trans\": \"He\",\n",
      "        \"gloss\": \"son\",\n",
      "        \"part_of_speech\": \"subs\"\n",
      "    },\n",
      "    \"Psalmi_\\u05d9\\u05d4\\u05d5\\u05d4/\": {\n",
      "        \"id\": 4,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        1,\n",
      "                        8,\n",
      "                        11,\n",
      "                        17,\n",
      "                        19,\n",
      "                        22\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        2,\n",
      "                        4,\n",
      "                        5,\n",
      "                        6,\n",
      "                        8,\n",
      "                        9\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        213,\n",
      "                        232,\n",
      "                        241,\n",
      "                        255,\n",
      "                        267,\n",
      "                        280\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"nametype\": \"pers\",\n",
      "        \"lexeme\": \"\\u05d9\\u05d4\\u05d5\\u05d4/\",\n",
      "        \"gloss\": \"YHWH\",\n",
      "        \"part_of_speech\": \"nmpr\"\n",
      "    },\n",
      "    \"Psalmi_\\u05d0\\u05d1\\ufb2a\\u05dc\\u05d5\\u05dd/\": {\n",
      "        \"id\": 2,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        1\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        1\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        211\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"nametype\": \"pers\",\n",
      "        \"lexeme\": \"\\u05d0\\u05d1\\ufb2a\\u05dc\\u05d5\\u05dd/\",\n",
      "        \"gloss\": \"Absalom\",\n",
      "        \"part_of_speech\": \"nmpr\"\n",
      "    },\n",
      "    \"Psalmi_\\u05dc_unique8\": {\n",
      "        \"suffix\": \"+\\u05b9\\u05d5\",\n",
      "        \"id\": 8,\n",
      "        \"occurrence\": {\n",
      "            \"Psalmi\": {\n",
      "                \"3\": {\n",
      "                    \"sentence_nr\": [\n",
      "                        6\n",
      "                    ],\n",
      "                    \"verse\": [\n",
      "                        3\n",
      "                    ],\n",
      "                    \"word_nr\": [\n",
      "                        226\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"lexeme\": \"\\u05dc\",\n",
      "        \"suffix_trans\": \"He\",\n",
      "        \"gloss\": \"to\",\n",
      "        \"part_of_speech\": \"prep\"\n",
      "    },\n",
      "    \"Psalmi_\\u05e2\\u05e0\\u05d4[_unique14\": {\n",
      "        \"pgn\": \"p3msg\",\n",
      "        \"suffix\": \"+\\u05b5\\u05e0\\u05b4\\u\n"
     ]
    }
   ],
   "source": [
    "# show what's in a dict in a readable way (show first 1000 char)\n",
    "import json\n",
    "print(json.dumps(unique_nodes, sort_keys=False, indent=4)[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26m 03s Done\n"
     ]
    }
   ],
   "source": [
    "def add_edge(G, src_node, tgt_node):    \n",
    "    weight = 0\n",
    "    sentence_weight = 0\n",
    "    word_weight = 0\n",
    "    \n",
    "    # if same book->chapter in src and tgt node\n",
    "    for book in src_node[\"occurrence\"].keys():\n",
    "        for chapter in src_node[\"occurrence\"][book].keys():\n",
    "            if tgt_node[\"occurrence\"][book][chapter]:\n",
    "                # compare sentence nrs to get sentence_weight\n",
    "                for sentence_src in src_node[\"occurrence\"][book][chapter][\"sentence_nr\"]:\n",
    "                    for sentence_tgt in tgt_node[\"occurrence\"][book][chapter][\"sentence_nr\"]:\n",
    "                        sentence_weight += get_weight_sentence(sentence_src, sentence_tgt)\n",
    "                \n",
    "                # compare word nrs to get word_weight\n",
    "                for word_src in src_node[\"occurrence\"][book][chapter][\"word_nr\"]:\n",
    "                    for word_tgt in tgt_node[\"occurrence\"][book][chapter][\"word_nr\"]:\n",
    "                        word_weight += get_weight_word(word_src, word_tgt)\n",
    "    \n",
    "    sentence_weight = round(sentence_weight,2)\n",
    "    word_weight = round(word_weight,2)\n",
    "    weight = round(sentence_weight + word_weight, 2)\n",
    "    \n",
    "    if sentence_weight > min_edge_weight or word_weight > min_edge_weight:\n",
    "        G.add_edge(\n",
    "            src_node[\"id\"],\n",
    "            tgt_node[\"id\"],\n",
    "            weight = weight,\n",
    "            sentence_weight = sentence_weight,\n",
    "            word_weight = word_weight\n",
    "        )\n",
    "        \n",
    "    return G\n",
    "\n",
    "def add_node(G, node):\n",
    "    nametype, suffix, suffix_trans, pgn, occurrence = '', '', '', '', ''\n",
    "\n",
    "    if node[\"nametype\"]:\n",
    "        nametype = node[\"nametype\"]\n",
    "    if node[\"suffix\"]:\n",
    "        suffix = node[\"suffix\"]\n",
    "        suffix_trans = node[\"suffix_trans\"]\n",
    "    if node[\"pgn\"]:\n",
    "        pgn = node[\"pgn\"]\n",
    "    for book in node[\"occurrence\"].keys():\n",
    "        for chapter in node[\"occurrence\"][book].keys():\n",
    "            for verse in node[\"occurrence\"][book][chapter][\"verse\"]:\n",
    "                occurrence += '{}_{}_{},'.format(book, chapter, verse)\n",
    "\n",
    "    G.add_node(\n",
    "        node[\"id\"],\n",
    "        gloss = node[\"gloss\"],\n",
    "        lexeme = node[\"lexeme\"],\n",
    "        part_of_speech = node[\"part_of_speech\"],\n",
    "        nametype = nametype,\n",
    "        suffix = suffix,\n",
    "        suffix_trans = suffix_trans,\n",
    "        pgn = pgn,\n",
    "        occurrence = occurrence\n",
    "    )\n",
    "\n",
    "    return G\n",
    "\n",
    "def create_network(unique_nodes, r_book='', r_chapter=''):\n",
    "    # create list with only nodes for current chapter/book/bible\n",
    "    selected_nodes = []\n",
    "    for node in unique_nodes.values():\n",
    "        if (node[\"occurrence\"][r_book][r_chapter] or\n",
    "            (node[\"occurrence\"][r_book] and not r_chapter) or\n",
    "            (not r_book and not r_chapter)):\n",
    "            \n",
    "            selected_nodes.append(node)\n",
    "            \n",
    "    # create graph\n",
    "    G = nx.Graph()\n",
    "    for src_idx in range(len(selected_nodes)):\n",
    "        src_node = selected_nodes[src_idx]\n",
    "        G = add_node(G, src_node)\n",
    "        \n",
    "        for tgt_idx in range(src_idx + 1, len(selected_nodes)):\n",
    "            tgt_node = selected_nodes[tgt_idx]\n",
    "            G = add_edge(G, src_node, tgt_node)\n",
    "        \n",
    "    return G\n",
    "\n",
    "if network_range == \"chapter\":\n",
    "    for r_book, r_chapters in bible_index.items():\n",
    "        for r_chapter in r_chapters:\n",
    "            G = create_network(unique_nodes, r_book, r_chapter)\n",
    "            nx.write_gexf(G, \"{}Bible_{}_{}_{}.gexf\".format(\n",
    "                    path,\n",
    "                    r_book,\n",
    "                    r_chapter,\n",
    "                    time.time()\n",
    "                ),\n",
    "                encoding = \"utf-8\",\n",
    "                prettyprint=True\n",
    "            )\n",
    "elif network_range == \"book\":\n",
    "    for r_book in bible_index.keys():\n",
    "        G = create_network(unique_nodes, r_book)\n",
    "        nx.write_gexf(G, \"{}Bible_{}_{}.gexf\".format(\n",
    "                path,\n",
    "                r_book,\n",
    "                time.time()\n",
    "            ),\n",
    "            encoding = \"utf-8\",\n",
    "            prettyprint=True\n",
    "        )\n",
    "else:\n",
    "    G = create_network(unique_nodes)\n",
    "    nx.write_gexf(G, \"{}Bible_{}.gexf\".format(\n",
    "            path,\n",
    "            time.time()\n",
    "        ),\n",
    "        encoding = \"utf-8\",\n",
    "        prettyprint=True,\n",
    "        version='1.1draft'\n",
    "     )\n",
    "    \n",
    "msg(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
